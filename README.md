# GCP-DataProc-Pyspark-Churn-Prediction

# ETL Pipeline with Data Cleaning, Analysis, and Churn Prediction

This project implements an ETL (Extract, Transform, Load) pipeline using PySpark to extract data from a PostgreSQL database, clean and analyze the data, and return the clean data to the database. The project also includes Docker containers and Dockerfiles for easy deployment, along with pgAdmin for managing the PostgreSQL database. Additionally, the project includes data visualization using Matplotlib and Seaborn, data manipulation with Pandas, and a churn prediction model using Decision Trees with hyperparameter tuning.

## Table of Contents
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Data Cleaning and Analysis](#data-cleaning-and-analysis)
- [Churn Prediction Model](#churn-prediction-model)
- [Docker Deployment](#docker-deployment)

## Requirements
To run this project, you'll need the following requirements:
- Python 3.x
- PySpark
- Pandas
- Matplotlib
- Seaborn
- PostgreSQL
- pgAdmin
- Docker

## Installation
1. Clone this repository to your local machine.
2. Install the required dependencies by running the following command:
